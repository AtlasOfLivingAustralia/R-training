---
title: "Sharing biodiversity data with `galaxias`"
author: "Peggy Newman, Dax Kellie & Martin Westgate
  <br>
  ![](images/ALA_Logo.png){style='width: auto; height: 150px; margin-top: 80px; padding-left: 20px; padding-right: 20px'}![](images/NCRIS_logo.png){style='width: auto; height: 150px; margin-top: 80px; padding-left: 20px; padding-right: 20px'} ![](images/CSIRO_logo.png){style='width: auto; height: 150px; margin-top: 80px; padding-left: 20px; padding-right: 20px'}"
format:
  revealjs: 
    theme: [default, custom.scss] 
    transition: fade
editor: visual
editor_options: 
  chunk_output_type: console
---

## Darwin Core

```{r, echo = FALSE}
#| label: quietly-add-fontawesome
#| echo: FALSE
fontawesome::fa_html_dependency()
```

```{r}
#| label: quitely-load-packages
#| echo: FALSE
library(readxl)
library(readr)
library(dplyr)
library(janitor)
library(tidyr)
library(tibble)
library(zip)
library(galah)

# load galaxias remotely WHILE TESTING ONLY
current_workspace <- getwd()
setwd("/Users/wes186/Documents/Work/Development/AtlasOfLivingAustralia/galaxias")
devtools::load_all()
setwd(current_workspace)
rm(current_workspace)
```

An *archive* is a `.zip` file containing three things:
<br>
<br>

```{=html}
<table class="table table-borderless-center">
  <tbody>
    <tr>
      <td>{{< fa frog size=3x >}}</td>
      <td>{{< fa clipboard size=3x >}}</td>
      <td>{{< fa list size=3x >}}</td>
    </tr>
    <tr>
      <td>data<br>csv format</td>
      <td>metadata<br>eml format</td>
      <td>schema<br>xml format</td>
    </tr>
  </tbody>
</table>
```

## Process
<br>
<br>
```{=html}
<table class="table table-borderless-center">
  <tbody>
    <tr>
      <td>{{< fa frog size=2x >}}</td>
      <td>{{< fa clipboard size=2x >}}</td>
      <td>{{< fa list size=2x >}}</td>
      <td>{{< fa folder-closed size=2x >}}</td>
      <td>{{< fa paper-plane size=2x >}}</td>
    </tr>
    <tr>
      <td>data</td>
      <td>metadata</td>
      <td>schema</td>
      <td>archive</td>
      <td>validate</td>
    </tr>
    <tr>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
  </tbody>
</table>
```

## Data
Create an example dataset

```{r}
#| label: example-tibble
#| echo: TRUE
library(tibble)
df <- tibble(
  latitude = c(-35.310, -35.273),
  longitude = c(149.125, 149.133),
  date = c("14-01-2023", "15-01-2023"),
  time = c("10:23", "11:25"),
  species = c("Callocephalon fimbriatum", "Eolophus roseicapilla"))
```

## Data
How should we convert this dataset to Darwin Core?

```{r}
#| label: suggest-workflow
#| echo: TRUE
#| eval: FALSE
suggest_workflow(df)
```

![](images/workflow_screenshot.png)


## Data
If we follow that advice:
```{r}
#| label: enact-suggest-workflow
#| echo: TRUE
df |>
  use_occurrences(occurrenceID = sequential_id(),
                  basisOfRecord = "humanObservation") |> 
  use_coordinates(decimalLatitude = latitude, 
                  decimalLongitude = longitude) |>
  use_datetime(eventDate = lubridate::dmy(date),
               eventTime = lubridate::hm(time)) |>
  use_scientific_name(scientificName = species, 
                      taxonRank = "species")
```


## Process
<br>
<br>
```{=html}
<table class="table table-borderless-center">
  <tbody>
    <tr>
      <td>{{< fa frog size=2x >}}</td>
      <td>{{< fa clipboard size=2x >}}</td>
      <td>{{< fa list size=2x >}}</td>
      <td>{{< fa folder-closed size=2x >}}</td>
      <td>{{< fa paper-plane size=2x >}}</td>
    </tr>
    <tr>
      <td>data</td>
      <td>metadata</td>
      <td>schema</td>
      <td>archive</td>
      <td>validate</td>
    </tr>
    <tr>
      <td>{{< fa check size=3x >}}</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
  </tbody>
</table>
```

## Metadata
Generate a metadata file
```{r}
#| label: use-metadata
#| eval: FALSE
#| echo: TRUE
use_metadata() # creates the following file:
```

```{r}
#| label: print-metadata-md
#| echo: FALSE
readLines("metadata.md")[1:15] |>
  paste0("\n") |>
  cat()
```

## Metadata
Convert to EML
```{r}
#| label: build-metadata
#| echo: TRUE
#| eval: FALSE
#| class-output: hscroll
build_metadata() # creates the following file:
```

```{r}
#| label: print-metadata-xml
#| echo: FALSE
build_metadata()
readLines("./data/eml.xml")[1:15] |> # check resulting file
  paste0("\n") |>
  cat()
```

## Process
<br>
<br>
```{=html}
<table class="table table-borderless-center">
  <tbody>
    <tr>
      <td>{{< fa frog size=2x >}}</td>
      <td>{{< fa clipboard size=2x >}}</td>
      <td>{{< fa list size=2x >}}</td>
      <td>{{< fa folder-closed size=2x >}}</td>
      <td>{{< fa paper-plane size=2x >}}</td>
    </tr>
    <tr>
      <td>data</td>
      <td>metadata</td>
      <td>schema</td>
      <td>archive</td>
      <td>validate</td>
    </tr>
    <tr>
      <td>{{< fa check size=3x >}}</td>
      <td>{{< fa check size=3x >}}</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
  </tbody>
</table>
```

## Schema
Automated process for mapping files & fields

```{r}
#| label: build-schema
#| eval: FALSE
#| echo: TRUE
#| class-output: hscroll
build_schema()
```

```{r}
#| label: view-schema
#| echo: FALSE
build_schema()
readLines("./data/meta.xml")[1:15] |> # check resulting file
  paste0("\n") |>
  cat()
```

## Process
<br>
<br>
```{=html}
<table class="table table-borderless-center">
  <tbody>
    <tr>
      <td>{{< fa frog size=2x >}}</td>
      <td>{{< fa clipboard size=2x >}}</td>
      <td>{{< fa list size=2x >}}</td>
      <td>{{< fa folder-closed size=2x >}}</td>
      <td>{{< fa paper-plane size=2x >}}</td>
    </tr>
    <tr>
      <td>data</td>
      <td>metadata</td>
      <td>schema</td>
      <td>archive</td>
      <td>validate</td>
    </tr>
    <tr>
      <td>{{< fa check size=3x >}}</td>
      <td>{{< fa check size=3x >}}</td>
      <td>{{< fa check size=3x >}}</td>
      <td></td>
      <td></td>
    </tr>
  </tbody>
</table>
```


## Archive
Automated process for zipping the `/data` folder

```{r}
#| label: build-archive
#| echo: TRUE
#| class-output: hscroll
archive_location <- build_archive()

zip_list(archive_location)[, 1:4] |>
  as_tibble()
```

## Process
<br>
<br>
```{=html}
<table class="table table-borderless-center">
  <tbody>
    <tr>
      <td>{{< fa frog size=2x >}}</td>
      <td>{{< fa clipboard size=2x >}}</td>
      <td>{{< fa list size=2x >}}</td>
      <td>{{< fa folder-closed size=2x >}}</td>
      <td>{{< fa paper-plane size=2x >}}</td>
    </tr>
    <tr>
      <td>data</td>
      <td>metadata</td>
      <td>schema</td>
      <td>archive</td>
      <td>validate</td>
    </tr>
    <tr>
      <td>{{< fa check size=3x >}}</td>
      <td>{{< fa check size=3x >}}</td>
      <td>{{< fa check size=3x >}}</td>
      <td>{{< fa check size=3x >}}</td>
      <td></td>
    </tr>
  </tbody>
</table>
```

## Validate
```{r}
#| label: hidden-gbif-passwords
#| echo: FALSE
galaxias_config(gbif = list(
    username = "atlasoflivingaustralia",
    email = "ala4r@ala.org.au",
    password = "galah-gbif-test-login"))
```


```{r}
#| label: gbif-password-example
#| eval: FALSE
#| echo: TRUE
galaxias_config(gbif = list(username = "a_gbif_user",
                            email = "my@email.com",
                            password = "a_secure_password"))
```

```{r}
#| label: gbif-validate
#| echo: TRUE
# validator_result <- validate_archive(archive_location)
```

## Process
<br>
<br>
```{=html}
<table class="table table-borderless-center">
  <tbody>
    <tr>
      <td>{{< fa frog size=2x >}}</td>
      <td>{{< fa clipboard size=2x >}}</td>
      <td>{{< fa list size=2x >}}</td>
      <td>{{< fa folder-closed size=2x >}}</td>
      <td>{{< fa paper-plane size=2x >}}</td>
    </tr>
    <tr>
      <td>data</td>
      <td>metadata</td>
      <td>schema</td>
      <td>archive</td>
      <td>validate</td>
    </tr>
    <tr>
      <td>{{< fa check size=3x >}}</td>
      <td>{{< fa check size=3x >}}</td>
      <td>{{< fa check size=3x >}}</td>
      <td>{{< fa check size=3x >}}</td>
      <td>{{< fa check size=3x >}}</td>
    </tr>
  </tbody>
</table>
```

## Publishing
The ALA publishing API is not yet production ready.<br>
Other options include:

- email your `.zip` file directly
- publish on [https://zenodo.org](https://zenodo.org) and sending us a link
- release public-safe data via [GitHub](https://github.com)

Then let us know at [data_management@ala.org.au](mailto:data_management@ala.org.au)


## {background-color="#1B5D81"}
<br>
<br>
<br>
<br>
<h2>Worked example</h2>
Converting ACT Frogwatch data to Event-core


## Setup
Get an example dataset
<br>
<br>

> Westgate et al. (2016) Data from: *Citizen science program shows urban
> areas have lower occurrence of frog species, but not accelerated 
> declines.* [https://doi.org/10.5061/dryad.75s51](https://doi.org/10.5061/dryad.75s51)

<br>
We place raw data (`Frogwatch_dataset.xlsx`)<br>in the `data-raw` folder

## Setup
Load required packages
```{r}
#| label: show-packages
#| echo: TRUE
#| eval: FALSE
# ALA packages
library(galaxias) # formatting for Darwin Core
library(galah)    # download data from living atlases

# Other packages
library(readxl)   # read from .xlsx
library(readr)    # write to .csv
library(dplyr)    # data manipulation
library(tidyr)    # data cleaning
library(janitor)  # more data cleaning
library(tibble)   # tibbles
library(zip)      # handle .zip files
```


## Data Import
Sites
```{r}
#| label: read-sites
#| echo: TRUE
sites <- read_xlsx("data-raw/Frogwatch_dataset.xlsx", 
                   sheet = "sites") |>
  clean_names()
glimpse(sites)
```

## Setup
Establish an RStudio project

```{r}
#| label: visible-setup
#| eval: FALSE
#| echo: TRUE
galaxias_project()
```
<br>
```
├── README.md                        : Description of the repository
├── metadata.md                      : Boilerplate metadata statement for this project
├── projectname.Rproj                : RStudio project file
├── data-raw                         : Folder to store source data
└── data                             : Folder to store processed data
```

## Data Import
Species
```{r}
#| label: read-species
#| echo: TRUE
spp <- read_xlsx("data-raw/Frogwatch_dataset.xlsx", 
                 sheet = "species list") |>
  clean_names()
spp
```

## Data Import
Observations

```{r}
#| label: read-observations
#| echo: TRUE
obs <- read_xlsx("data-raw/Frogwatch_dataset.xlsx", 
                 sheet = "observations") |>
  clean_names()
glimpse(obs)
```


## Interlude
<br>
<br>
We have two options here:

- **occurrence**-based dataset: all observations are assumed to be independent (ALA default)
- **event**-based dataset: simultaneous observations are grouped together

## Interlude 
<br>
<br>
Most multi-species surveys are 'event'-like, so we'll use 'event core', which requires we split our data into two files:

- **events.csv** contains site visits and attributes.
- **occurrences.csv** contains observations made during those visits, *including absences*.


## Events
<br>
<br>
In this case, each *event* is a 5-minute audio survey for calling frogs. Frogs
are recorded as **present** or **absent** (i.e. no abundance data)

## Events
Add an `eventID` field

```{r}
#| label: add-eventID
#| echo: TRUE
obs <- obs |>
  select(site_code, year, any_of(spp$abbreviation)) |>
  use_events(eventID = composite_id(sequential_id(),
                                    site_code,
                                    year)) |>
  relocate(eventID, .before = 1)
print(obs, n = 5)
```

## Events
Add spatial fields

```{r}
#| label: add-spatial
#| echo: TRUE
obs <- obs |>
  left_join(select(sites, site_code, latitude, longitude),
            by = "site_code") |>
  use_coordinates(latitude, 
                  longitude,
                  geodeticDatum = "WGS84",
                  coordinateUncertaintyInMeters = 30) |>
  relocate(decimalLatitude, decimalLongitude, .after = eventID) 
print(obs, n = 5)
```

## Events
Save out

```{r}
#| label: write_events
#| echo: TRUE
events <- obs |>
  select(any_of(event_terms()))
write_csv(events, "data/events.csv")
check_dataset(events)
```


## Occurrences
<br>
<br>
Each *occurrence* is a datum of whether a species was, or was not, detected. 
Occurrences are **nested within events**.

## Occurrences
Restructure to long-form

```{r}
#| label: occurrences-pivot_longer
#| echo: TRUE
obs_long <-  obs |>
  select(eventID, any_of(spp$abbreviation)) |>
  pivot_longer(cols = spp$abbreviation,
               names_to = "abbreviation") |>
  left_join(spp, by = "abbreviation") |>
  select(-abbreviation) |>
  relocate(value, .after = last_col())

print(obs_long, n = 5)
```

## Occurrences
**Optional:** Check against ALA taxonomy

```{r}
#| label: search_taxa
#| echo: TRUE
taxa <- search_taxa(spp$scientific_name)
taxa
```

## Occurrences 
**Optional:** Join taxonomy

```{r}
#| label: join-occurrences-taxonomy
#| echo: TRUE
obs_long <- obs_long |>
 left_join(select(taxa, -search_term, -species, -vernacular_name, -issues, -match_type),
           by = "scientific_name")

print(obs_long, n = 5)
```

## Occurrences
Swap to Darwin Core headers

```{r}
#| label: occurrences-to-dwc
#| echo: TRUE
obs_long <- obs_long |>
 use_occurrences(
   occurrenceID = composite_id(eventID, sequential_id()),
   basisOfRecord = "humanObservation",
   occurrenceStatus = dplyr::case_when(value == 1 ~ "present",
                                       .default = "absent")) |>
 use_scientific_name(scientificName = scientific_name,
                     scientificNameAuthorship = scientific_name_authorship,
                     taxonRank = rank) |>
 use_taxonomy(vernacularName = common_name) |>
 rename(taxonConceptID = taxon_concept_id)
```

## Occurrences
Export

```{r}
#| label: write-occurrences
#| echo: TRUE
occurrences <- obs_long |>
  select(any_of(occurrence_terms()))
write_csv(occurrences, file = "./data/occurrences.csv")
check_dataset(occurrences)
```

## Summary
Two datasets linked by `eventID`

::: columns
::: {.column width="50%"}
```{r}
#| label: glimpse-events
#| echo: TRUE
glimpse(events, width = 10)
```
:::

::: {.column width="50%"}
```{r}
#| label: glimpse-occurrences
#| echo: TRUE
glimpse(occurrences, width = 10)
```
:::
:::